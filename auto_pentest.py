import torch
import numpy as np
from transformers import GPT2LMHeadModel, GPT2Tokenizer
from typing import Dict, List, Optional
import requests
import re
import random
from datetime import datetime
import hashlib

class PentestAI:
    def __init__(self, model_path: str = "gpt2-medium"):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.tokenizer = GPT2Tokenizer.from_pretrained(model_path)
        self.model = GPT2LMHeadModel.from_pretrained(model_path).to(self.device)
        self.model.eval()
        
        # Load CVE patterns
        self.cve_patterns = self._load_cve_patterns()
        
    def _load_cve_patterns(self) -> Dict:
        """Load attack patterns from knowledge base"""
        return {
            'sql_injection': {
                'patterns': [r'SELECT.*FROM.*WHERE.*\$\{.*\}', r'UNION.*SELECT'],
                'severity': 9.5
            },
            'xss': {
                'patterns': [r'<script>.*</script>', r'onerror=.*'],
                'severity': 8.0
            },
            'rce': {
                'patterns': [r'popen\(.*\)', r'\./.*\$'],
                'severity': 10.0
            }
        }

    def generate_payload(self, cve: str, context: Dict) -> Dict:
        """Generate context-aware exploit payload"""
        prompt = f"Generate {cve} exploit for {context.get('target')} with constraints {context.get('constraints')}:"
        
        input_ids = self.tokenizer.encode(prompt, return_tensors="pt").to(self.device)
        
        with torch.no_grad():
            output = self.model.generate(
                input_ids,
                max_length=200,
                temperature=0.7,
                top_k=50,
                top_p=0.9,
                num_return_sequences=3,
                pad_token_id=self.tokenizer.eos_token_id
            )
        
        payloads = [self.tokenizer.decode(seq, skip_special_tokens=True) 
                   for seq in output]
        
        # Validate payloads against known patterns
        validated = []
        for payload in payloads:
            score = self._score_payload(payload)
            if score > 0.6:  # Confidence threshold
                validated.append({
                    'payload': payload,
                    'score': score,
                    'signature': hashlib.sha256(payload.encode()).hexdigest()
                })
        
        return {
            'cve': cve,
            'context': context,
            'generated_at': datetime.utcnow().isoformat(),
            'payloads': validated
        }

    def _score_payload(self, payload: str) -> float:
        """Score payload effectiveness using pattern matching"""
        max_score = 0.0
        for vuln_type, data in self.cve_patterns.items():
            for pattern in data['patterns']:
                if re.search(pattern, payload, re.IGNORECASE):
                    max_score = max(max_score, data['severity'] * 0.1)
        return min(max_score, 1.0)

    def auto_scan(self, target: str) -> Dict:
        """Automated vulnerability assessment"""
        # Phase 1: Reconnaissance
        recon = self._perform_recon(target)
        
        # Phase 2: Target Analysis
        analysis = self._analyze_target(recon)
        
        # Phase 3: Exploit Generation
        exploits = []
        for vuln in analysis.get('vulnerabilities', []):
            context = {
                'target': target,
                'vulnerability': vuln,
                'constraints': analysis.get('constraints')
            }
            exploits.append(self.generate_payload(vuln['type'], context))
        
        return {
            'target': target,
            'recon': recon,
            'analysis': analysis,
            'exploits': exploits,
            'risk_score': sum(v['severity']*0.1 for v in analysis.get('vulnerabilities', []))
        }

    def _perform_recon(self, target: str) -> Dict:
        """Gather target information"""
        # Mock implementation - replace with actual scans
        return {
            'open_ports': [80, 443, 8080],
            'technologies': ['nginx', 'react', 'node.js'],
            'headers': {'Server': 'nginx/1.18.0'},
            'dns_info': []
        }

    def _analyze_target(self, recon_data: Dict) -> Dict:
        """Analyze recon data for vulnerabilities"""
        # ML-based pattern matching
        tech_stack = ' '.join(recon_data['technologies'])
        input_text = f"Analyze security vulnerabilities for {tech_stack}:"
        
        input_ids = self.tokenizer.encode(input_text, return_tensors="pt").to(self.device)
        
        with torch.no_grad():
            output = self.model.generate(
                input_ids,
                max_length=300,
                temperature=0.5,
                top_p=0.9,
                num_return_sequences=1
            )
        
        analysis = self.tokenizer.decode(output[0], skip_special_tokens=True)
        
        # Extract vulnerabilities from analysis
        detected = []
        for vuln_type, data in self.cve_patterns.items():
            if any(re.search(p, analysis, re.IGNORECASE) for p in data['patterns']):
                detected.append({
                    'type': vuln_type,
                    'severity': data['severity'],
                    'confidence': random.uniform(0.7, 0.95)
                })
        
        return {
            'vulnerabilities': detected,
            'constraints': self._extract_constraints(analysis),
            'raw_analysis': analysis
        }

    def _extract_constraints(self, analysis: str) -> List[str]:
        """Extract environmental constraints from analysis"""
        constraints = []
        if 'WAF' in analysis:
            constraints.append('web_application_firewall')
        if 'CORS' in analysis:
            constraints.append('cross_origin_restrictions')
        if 'HTTPS' in analysis:
            constraints.append('encrypted_transport')
        return constraints

# Example Usage
if __name__ == "__main__":
    # Initialize systems
    compressor = KnowledgeCompressor()
    pentester = PentestAI()
    
    # Sample knowledge base
    knowledge = {
        "CVE-2023-1234": "Remote Code Execution in Apache Server",
        "CVE-2023-5678": "SQL Injection in Django Admin",
        "_meta": {"version": "test"}
    }
    
    # Demonstrate compression
    compressed, stats = compressor.compress(knowledge)
    print(f"Compression stats: {stats}")
    
    # Demonstrate pentesting
    scan_report = pentester.auto_scan("example.com")
    print(f"Top vulnerability: {scan_report['analysis']['vulnerabilities'][0]}")
